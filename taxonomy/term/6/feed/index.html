<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xml:base="http://cmsc411.com"  xmlns:dc="http://purl.org/dc/elements/1.1/">
<channel>
 <title>CMSC411 - Memory Hierarchy and Cache</title>
 <link>http://cmsc411.com/topics/memory-hierarchy-and-cache</link>
 <description> 
Online Resources:
Virtual Memory: Java Applet Step-Through
Virtual Memory Underground
Student Projects:
Escape from Reality (Virtual Memory Tutorial)
Plenty of Information on Cache
Outer Gate (an in-depth look at memory and caches)
A Consumer&#039;s Guide to Modern Computer RAM
 
</description>
 <language>en</language>
<item>
 <title>Resources</title>
 <link>http://cmsc411.com/memory-hierarchy-and-cache/resources</link>
 <description>&lt;div class=&quot;field field-name-body field-type-text-with-summary field-label-hidden&quot;&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot; property=&quot;content:encoded&quot;&gt;&lt;ul&gt;&lt;li&gt;Structured Computer Organization, 5th Edition,  by Andrew S. Tanenbaum&lt;/li&gt;
&lt;li&gt;Memory Systems: Cache, DRAM, Disk, by Bruce Jacob, Spencer W. Ng, and David T. Wang&lt;/li&gt;
&lt;/ul&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description>
 <pubDate>Fri, 03 May 2013 23:23:30 +0000</pubDate>
 <dc:creator>mwollman</dc:creator>
 <guid isPermaLink="false">136 at http://cmsc411.com</guid>
 <comments>http://cmsc411.com/memory-hierarchy-and-cache/resources#comments</comments>
</item>
<item>
 <title>Implementation</title>
 <link>http://cmsc411.com/memory-hierarchy-and-cache/implementation</link>
 <description>&lt;div class=&quot;field field-name-body field-type-text-with-summary field-label-hidden&quot;&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot; property=&quot;content:encoded&quot;&gt;&lt;p&gt;In this section we will discuss the details of one possible way of implementing a virtual memory system. Remember, however, that this represents only one possible implementation, and the design space is very large.&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;h4&gt;Page Tables&lt;/h4&gt;
&lt;p&gt;As stated before, the virtual memory system knows the mappings between the virtual pages and the page frames. In our implementation, it does so using a &lt;strong&gt;page table&lt;/strong&gt;, a data structure with an entry for every mapping that the system must keep track of. It should be clear from the previous sections that the number of entries in the page table will be equal to the number of virtual pages. Each page table entry contains information about the mapping, including:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;strong&gt;Valid Bit:&lt;/strong&gt; The valid bit is one bit in the entry that specifies whether the virtual page resides in a page frame, or on the backing store. If the valid bit is 1, the virtual page is in memory; if it is 0, the virtual page is on the backing store, and the rest of the data in the page table entry is considered invalid.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Dirty Bit: &lt;/strong&gt;The dirty bit is one bit in the entry that specifies whether the virtual page has been written to since it was brought off the backing store into memory. Use of the dirty bit will be discussed later.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Page Frame Number:&lt;/strong&gt; The page frame number is the number of the physical page to which this virtual page is mapped. This is the data that is used to translate the virtual address into a physical one.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Other Page Info:&lt;/strong&gt; A page table entry also contains other fields, such as page permissions or whether the page is global, which are beyond the scope of this document.&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;In some implementations, a page table entry will also contain the number of the virtual page corresponding to the entry. However, this is an expensive method with a simple workaround. If the entries in the page table are ordered sequentially, with the first entry being for page 1, the second for page 2, and so on, then the virtual page number can be used to index into the page table. The virtual page of an entry is now implicitly defined by the position of the entry in the page table.&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p&gt;Now that we have our page table, we can use it whenever we need to do an address translation. Given a virtual address, we first split it into two parts, the page number and the offset. The offset is the &lt;em&gt;n&lt;/em&gt; lowest order bits of the address, where &lt;em&gt;n &lt;/em&gt;is the number of bits needed to index a whole page (in our case, 4 KiB pages require a 12 bit offset). The page number is the remaining bits of the address. The page number is used to index into the page table and aquire the page frame number. The page frame number is used to find the base of the physical page we need, and then the offset is added to this base to produce the full physical address.&lt;/p&gt;
&lt;p&gt;The astute reader may ask, &#039;If the page table exists in memory, how do we find the address of the page table without having to use the page table?&#039; The answer is, we don&#039;t. Unfortunately, at least some part of memory has to be &#039;wired down,&#039; or statically allocated for the page table. The page table is placed somewhere in physical memory, and a special register is given the base physical address of the page table. When indexing the page table, we actually add the offset for that index to the contents of this special register to find the entry we want.&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;h4&gt;Page Faults&lt;/h4&gt;
&lt;p&gt;In a previous section, we asked what would happen if an access occurred to a virtual page that was not currently in memory. We gave a generic answer, but here we will go into more detail given our implementation.&lt;/p&gt;
&lt;p&gt;When a page fault occurs, a special function is invoked, called the &lt;strong&gt;page fault handler&lt;/strong&gt;. It is the job of the page fault handler to set up the memory so that the user process can continue to execute. The first step is to make some space in the physical memory for the page that we need to bring in. The page fault handler looks through the pages currently in memory, and selects one to page out. In selecting which page to evict, we can borrow some algorithms from cache management (in fact, one can view the main memory as effectively being nothing more than a cache for the backing store):&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;strong&gt;&lt;span class=&quot;mw-headline&quot; id=&quot;B.C3.A9l.C3.A1dy.27s_Algorithm&quot;&gt;Bélády&#039;s&lt;/span&gt; Oracle:&lt;/strong&gt; As in cache management, the optimal algorithm is one that evicts the page that will be used the furthest in the future. However, this algorithm is impossible to achieve in practice, and merely serves as a metric for other, real-world algorithms.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Least Recently Used (LRU):&lt;/strong&gt; LRU dictates that the evicted page should be the one that has not been accessed for the longest time. The performance of this algorithm is fairly good, although it requires a bit of overhead in each page table entry to keep track of what was accessed when.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Random:&lt;/strong&gt; A random algorithm simply chooses a page to evict at random, with no regard to access time. This algorithm trades the performance of LRU for reduced overhead.&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt; &lt;/p&gt;
&lt;p&gt;In any case, once the page fault handler has selected a page to page out, it looks at the dirty bit of its page table entry. If the dirty bit is set, that means that the page frame has been written to and is inconsistent with the copy on the backing store, so it must be written out to the backing store. However, if the dirty bit is not set, the data in the page frame is identical to the data on the backing store, and we can save ourselves some time by simply throwing away the data in the page frame. Either way, the page frame is now unused, and we update the page table entry for the virtual page that was previously mapped to that page frame to indicate that it is on the backing store.&lt;/p&gt;
&lt;p&gt;Now that we have an empty page frame, we can copy the faulting virtual page off the backing store and into the page frame. Once this is done, we update the page table entry for the faulting virtual page to point to the page frame. Then, we make whatever instruction caused the page fault execute again. From the perspective of the process that caused the page fault, with the exception of a longer run time, nothing unusual has happened!&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;h4&gt;Demand Paging&lt;/h4&gt;
&lt;p&gt;So far, we have been making the assumption that as much of a program is read into memory as possible upon start. However, the page fault handler need not only be used when all of memory is full. Instead, we can modify the handler so that first it looks for any page frames that are not currently mapped by a virtual page. If it finds one, we don&#039;t have to bother evicting a page that is mapped. The implication of this is that we don&#039;t need all of a program in memory to execute it, only the parts that are currently being used. In fact, when the program is first loaded, the only page we have to load into main memory is the virtual page containing the program&#039;s starting address (we may also load the page that holds the top of the stack, as the likelihood that the program will use the stack is high). Loading only those virtual pages that we currently need into memory, and allowing ones that we no longer need to be paged out is known as &lt;strong&gt;demand paging&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;h4&gt;Pageable Page Tables&lt;/h4&gt;
&lt;p&gt;At this point we have a fully-functional virtual memory system. However, the page table represents a significant portion of the overhead. In the case of a system with 32-bit addresses, the maximum addressable memory is 4 GiB. Given that each page table entry covers 4 KiB (the size of a page), we need 2^20 page table entries to cover the entire virtual address space. Assuming that each entry is 4 bytes (a commonly used size), the page table will take up 4 MiB. In addition, similar to how we only need pieces of a program at any given time, we generally need only parts of the page table. The next step is simple: page the page table. We break the page table up into 4 KiB pages, and move it into the virtual memory space. As stated above, at least some portion of memory must be wired down, so we create another page table, the &lt;strong&gt;root page table&lt;/strong&gt;. The root page table is similar in structure to the page table we have already discussed, but instead of pointing to page frames, the entries of the root page table point to pieces of the page table. So, during the address translation process, we now break the virtual address into three pieces. Again, the offset is the 12 bytes needed to address a 4 KiB page. However, we now no longer know the location of the page table that contains the mapping for the virtual page we need. To find it, we take the 10 high-order bits (we use 10 bits because the 4 MiB page table, broken up into 4 KiB pages, consists of 1024 (or 2^10) pages) and use them to index into the root page table. The root page table entry tells us where to get the piece of the page table we want. We then use the remaining bits of the virtual address to index into the page table to generate a physical address for the page frame we need. As before, the offset is added to the page frame base address to calculate the final physical address. In this way we have reduced the explicit memory requirement of the virtual memory system from 4 MiB to a single page; only the root page table is wired down, and any pieces of the page table not currently needed can reside on the backing store.&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;h4&gt;TLB&lt;/h4&gt;
&lt;p&gt;Another way to improve our virtual memory implementation is the addition of a &lt;strong&gt;Translation Lookaside Buffer (TLB)&lt;/strong&gt;. The TLB functions as a cache of recently used virtual addresses. The &#039;tag&#039; of a TLB entry is the virtual page number, and the data of an entry is the page frame to which that virtual page maps. When a page fault occurs, not only do we bring the virtual page into memory, but we add an entry in the TLB for this mapping (general cache eviction strategies are employed when necessary). In this way, we can often save the trouble of indexing into the page tables to do the address translation, and save some time.&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description>
 <pubDate>Wed, 01 May 2013 04:26:29 +0000</pubDate>
 <dc:creator>mwollman</dc:creator>
 <guid isPermaLink="false">62 at http://cmsc411.com</guid>
 <comments>http://cmsc411.com/memory-hierarchy-and-cache/implementation#comments</comments>
</item>
<item>
 <title>Paging</title>
 <link>http://cmsc411.com/memory-hierarchy-and-cache/paging</link>
 <description>&lt;div class=&quot;field field-name-body field-type-text-with-summary field-label-hidden&quot;&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot; property=&quot;content:encoded&quot;&gt;&lt;p&gt;As stated in a previous section, the virtual memeory system involves introducing a layer of abstraction between the user and the physical memory. Doing so necessitates replacing the single address space of direct-mapped memory with two distinct spaces, the &lt;strong&gt;virtual address space&lt;/strong&gt; and the &lt;strong&gt;physical address space&lt;/strong&gt;. The virtual address space is the one used by a running process to address the memory. The physical address space is the one used by the system to address the physical memory. This may seem like a trivial distinction, and in a system employing direct-mapped memory, it is. In such a system, an address in the virtual memory space corresponds to the same address in the physical address space (at this point it should be clear why it is referred to as direct-mapped memory), so we really haven&#039;t bought ourselves anything. However, the virtual memory system steps in to break the direct link between these two address spaces.&lt;/p&gt;
&lt;p&gt;In a system using virtual memory, addresses within the virtual address space are referred to as &lt;strong&gt;logical addresses&lt;/strong&gt;. Logical addresses are the addresses used by processes running on the machine, and do not necessarily (though they may!) correspond directly to the addresses of the physical address space. Addresses within the physical address space are referred to as &lt;strong&gt;physical addresses&lt;/strong&gt;. Physical addresses are the addresses used to find a value in the actual memory hardware. The virtual memory system acts as a translator between these two address spaces. For example, when a process tries to perform a read, the logical address for the read is handed to the virtual memory hardware, which translates the logical address into the physical address at which the data in question resides, and the read can be performed successfully.&lt;/p&gt;
&lt;hr /&gt;&lt;p&gt;&lt;strong&gt;NOTE:&lt;/strong&gt; For the remainder of this document, we will be discussing the virtual and physical address spaces as discrete concepts, which in terms of system design, they are. However, on a system which implements virtual memory, the user will have no indication that the logical addresses do not correspond directly to physical addresses. The address translation, and in fact the virtual memory system as a whole, is said to be &lt;strong&gt;transparent&lt;/strong&gt;, in that it is undetectable by the user.&lt;/p&gt;
&lt;hr /&gt;&lt;p&gt; &lt;/p&gt;
&lt;h4&gt;Paging&lt;/h4&gt;
&lt;p&gt;Now that we have decoupled the virtual and physical address spaces, a few new possibilites are open to us. First, as stated, the virtual address space no longer has to map directly onto the physical address space. This necessitates some method of keeping track of, for every virtual address, where in the physical address space it is mapped. In theory, it would be possible to do this independently for every single address, but the amount of space required to hold all of those mappings would be prohibitively expensive. So how do we keep track of all these mappings? The answer lies in a technique called &lt;strong&gt;paging&lt;/strong&gt;. In a memory-management scheme that employs paging, both the virtual and physical address spaces are divided into blocks of a fixed size, called pages (no physical change is made, the division is merely a theoretical one). The size of a page varies from system to system, but for the sake of this document we will consider the standard page size to be 4 KiB.&lt;/p&gt;
&lt;p&gt;Once we have divided up the address space, we can map entire virtual pages onto phyisical pages (physical pages are also referred to as &lt;strong&gt;page frames&lt;/strong&gt;). We dictate that all the addresses within a virtual page are mapped to the corresponding addresses in the page frame to which the virtual page is mapped. In this way, we reduce the number of mappings we have to keep track of by a factor of 4096!&lt;/p&gt;
&lt;hr /&gt;&lt;p&gt;&lt;strong&gt;NOTE:&lt;/strong&gt; The methods by which the mappings between virtual pages and page frames are maintained within the virtual memory system are non-trivial, but the details vary from system to system. For now, this document will remain agnostic to the way in which we keep track of these mappings. A later section will detail an example implementation.&lt;/p&gt;
&lt;hr /&gt;&lt;p&gt;While paging the memory seems like a cool idea, we still really haven&#039;t gained anything, but we have added another layer of complication. However, there is another aspect of the virtual memory system which we have not discussed yet. While the size of the physical address space is limited by the amount of physical memory actually present in the system, the virtual address space has no such restriction. In fact, the only limit to the size of the virtual address space is the number of bits available to be used as an address.&lt;/p&gt;
&lt;p&gt;Obviously, there is a problem here. How can a process think that there is more memory in the system then there actually is?  What happens when the memory for a program is larger than the memory provided by the system? The method used by the virtual memory system to solve this issue is similar to the method of overlays mentioned in a previous section. Clearly, the number of virtual pages that are mapped to page frames at any given time can be no greater than the number of page frames that exist in the physical memory. In the case that the virtual address space is larger than the physical address space, only a portion of the virtual pages will be mapped to page frames. The virtual memory system will remember that the rest of the virtual pages currently reside on the &lt;strong&gt;backing store&lt;/strong&gt; (the persistent memory used to store the primary copy of the code and non-transient data of a process). In the event of a memory access, the virtual memory system checks the mapping for the virtual page associated with that address. If the virtual page is currently mapped to page frame, the address is simply translated, and no further action is taken. However, if the virtual page currently resides on the backing store, it has to be read into memory so it can be accessed (an attempted access to a virtual page which is not currently mapped to a page frame is called a &lt;strong&gt;page fault&lt;/strong&gt;). To handle the page fault, the virtual memory system first looks through the virtual pages that are currently mapped to a page frame and picks one to copy back onto the backing store, freeing the page frame associated with that page (the act of moving a virtual page from a page frame to the backing store is called a &lt;strong&gt;page-out&lt;/strong&gt;; methods for selecting a page to page out will be discussed in a later section). The virtual page corresponding to the address which caused the page fault can then be copied from the backing store into the newly freed page frame, after which the virtual memory system updates its mappings to reflect these changes. The process that caused the page fault can then resume execution without ever knowing that anything unusual has happened!&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p&gt;While paging shares traits with the overlay method, overlays saddled the user with the task of switching out blocks of memory when required. A virtual memory system that employs paging, however, is entirely transparent to the user. In fact, from the user&#039;s perspective, a computer with a virtual memory system is nearly indistinguishable from a system with a direct-mapped physical memory large enough to cover the entire virtual address space. In fact, the only way for the user to detect the presence of a virtual memory system would be complex timing tests.&lt;/p&gt;
&lt;p style=&quot;text-align: right;&quot;&gt;Next: &lt;a href=&quot;http://cmsc411.com/memory-hierarchy-and-cache/implementation&quot;&gt;Implementation&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description>
 <pubDate>Wed, 01 May 2013 04:25:29 +0000</pubDate>
 <dc:creator>mwollman</dc:creator>
 <guid isPermaLink="false">60 at http://cmsc411.com</guid>
 <comments>http://cmsc411.com/memory-hierarchy-and-cache/paging#comments</comments>
</item>
<item>
 <title>Direct-Mapped Memory</title>
 <link>http://cmsc411.com/memory-hierarchy-and-cache/direct-mapped-memory</link>
 <description>&lt;div class=&quot;field field-name-body field-type-text-with-summary field-label-hidden&quot;&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot; property=&quot;content:encoded&quot;&gt;&lt;h2&gt;Introduction&lt;/h2&gt;
&lt;p&gt;To understand the virtual memory system, and why it&#039;s an improvement, we must first understand the base on which the virtual memory system is built. One of the key concepts when discussing memory systems is that of an &lt;strong&gt;address space&lt;/strong&gt;, or the set of distinct addresses that you can produce given a certain number of address bits. For example, if a system uses 8 bits for an address, then the highest possible address will be 2^8 - 1, so the address space will consist of the addresses 0x00000000 to 0xFFFFFFFF.&lt;/p&gt;
&lt;h4&gt;Direct-Mapped Memory&lt;/h4&gt;
&lt;p&gt;In the early days of computers, memory-management schemes were fairly simple, utilizing what is called &lt;strong&gt;direct-mapped memory&lt;/strong&gt;. Direct-mapped memory means that an address used in a program translates directly to the address used to find the value in the memory. Early computers reserved areas of the address space for different tasks; some of the address space was dedicated to system tasks, and some was given to the user. The part of the address space that corrseponded to addresses higher than the amount of physical memory actually present in the system was considered invalid, and an access to it would cause an error.&lt;/p&gt;
&lt;h4&gt;Drawbacks&lt;/h4&gt;
&lt;p&gt;Obviously, this strategy had some serious issues. For one, it was up to the user to find a way to fit their code into the static, small amount of space provided. In addition, since the address space extended beyond the end of the physical memory, the most significant bits of an address were effectively wasted.&lt;/p&gt;
&lt;p&gt;One method that came about for getting around the space limitation was the use of overlays. The user could split their code into sections, or overlays, the same size as the portion of the address space allocated for the user. Upon startup, the user could load the first overlay into memory. Once an address not covered by the current overlay was required, the user could store the current overlay and load the next one. While this worked, it was arduous for the programmer to have to manage all of this, and the overhead of switching out overlays was significant. However, this strategy laid the groundwork for the development of the method that is the backbone of the virtual memory system, namely paging.&lt;/p&gt;
&lt;p style=&quot;text-align: right;&quot;&gt;Next: &lt;a href=&quot;http://cmsc411.com/memory-hierarchy-and-cache/paging&quot;&gt;Paging&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description>
 <pubDate>Mon, 08 Apr 2013 19:27:14 +0000</pubDate>
 <dc:creator>mwollman</dc:creator>
 <guid isPermaLink="false">23 at http://cmsc411.com</guid>
 <comments>http://cmsc411.com/memory-hierarchy-and-cache/direct-mapped-memory#comments</comments>
</item>
<item>
 <title>Virtual Memory</title>
 <link>http://cmsc411.com/memory-hierarchy-and-cache/virtual-memory</link>
 <description>&lt;div class=&quot;field field-name-body field-type-text-with-summary field-label-hidden&quot;&gt;&lt;div class=&quot;field-items&quot;&gt;&lt;div class=&quot;field-item even&quot; property=&quot;content:encoded&quot;&gt;&lt;p&gt;The virtual memory system is a memory-management scheme that is now ubiquitous in general purpose computers. It is a also becoming more common in mobile and embedded applications. The goal of virtual memory is to provide a layer of abstraction between the user and the physical memory. The goal of this page is to give the reader some insight into how virtual memory works, and the details of implementation.&lt;/p&gt;
&lt;h5&gt;Contents:&lt;/h5&gt;
&lt;ul&gt;&lt;li&gt;&lt;a href=&quot;http://cmsc411.com/memory-hierarchy-and-cache/direct-mapped-memory&quot;&gt;Direct-Mapped Memory&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://cmsc411.com/memory-hierarchy-and-cache/paging&quot;&gt;Paging&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://cmsc411.com/memory-hierarchy-and-cache/implementation&quot;&gt;Implementation&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;p style=&quot;text-align: right;&quot;&gt;Next: &lt;a href=&quot;http://cmsc411.com/memory-hierarchy-and-cache/direct-mapped-memory&quot;&gt;Direct-Mapped Memory&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description>
 <pubDate>Mon, 08 Apr 2013 19:26:52 +0000</pubDate>
 <dc:creator>mwollman</dc:creator>
 <guid isPermaLink="false">22 at http://cmsc411.com</guid>
 <comments>http://cmsc411.com/memory-hierarchy-and-cache/virtual-memory#comments</comments>
</item>
</channel>
</rss>
